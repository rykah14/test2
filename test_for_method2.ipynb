{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_for_method2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TbHagT2R8Wef1KIfBjiD_rVY_XhhpItN",
      "authorship_tag": "ABX9TyMIsdvcL4IHYHPjbKMGfLSy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rykah14/test2/blob/main/test_for_method2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# はじめに\n",
        "\n",
        "今回の研究はデータの組み合わせによる比較をメインに実験をした。\n",
        "\n",
        "データを準備し分類に必要なものだけ洗濯をした箇所最も重要と考える。\n",
        "\n",
        "そのためBERTの内部のパラメータの調整、エポック数の調整などは行なっておらず、Hugging Face の推奨する値、やり方で行なった。"
      ],
      "metadata": {
        "id": "QdS9j1L-1Kxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.事前準備\n",
        "\n",
        "1.  redditデータセットをGoogleドライブにアップロードする\n",
        "1.   ColaboratoryファイルをGoogleドライブに接続する(左のサイドバーからファイルアイコンを選択し、Googleドライブと接続するアイコンを押す)\n",
        "2.   このノートブックに Google ドライブのファイルへのアクセスを許可しますか？というポップアップが出るので許可を選択する\n",
        "\n",
        "Googleドライブにアップロードされたcsvファイルを読み込む際には、ColaboratoryとGoogleドライブを接続する必要がある\n",
        "\n",
        "※csvファイルの内容をColaboratory上で書き換えることは行わなかった\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fAsfD5KbxmFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.環境構築"
      ],
      "metadata": {
        "id": "KtAFd_Y2XrSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow　をインポートする　"
      ],
      "metadata": {
        "id": "mccUuJqtyRMq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJShceY_jYM"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU環境を構築する"
      ],
      "metadata": {
        "id": "cxNA4UaZyUnc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjC5oBSmko1",
        "outputId": "f1e4832f-5b2f-4fa5-af69-e702e63fd902"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformersのインストールを行う\n",
        "\n",
        "この作業をすることでHugging Face社の提供するBERTのツールが使えるようになる\n",
        "\n",
        "(https://huggingface.co/transformers/v2.2.0/index.html)\n",
        "\n",
        "BERT以外の自然言語処理のパッケージや画像処理のモデルもモデルもtransformers内に存在する"
      ],
      "metadata": {
        "id": "OwfSZ57TyYnB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFO1My4mv9Q",
        "outputId": "dec900c3-48ff-4a53-8218-64e15829f406"
      },
      "source": [
        "!pip install transformers　"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.データの準備"
      ],
      "metadata": {
        "id": "Olro2dfJXvO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前準備でGoogleドライブに格納したredditデータセットをColaboratory上に入力する。\n",
        "\n",
        "ここでGoogleドライブとColaboratoryファイルが接続されていないとエラーが発生する。\n",
        "\n",
        "文章数の出力、データの中身の一例の出力は任意であるが、これらを行うことによってデータの中身の概要を知ることができる。\n",
        "\n",
        "今回のredditデータセットであれば、文章データを表すものはbodyに格納されている、カテゴリー名を表すものはsubredditであると分かる。"
      ],
      "metadata": {
        "id": "u8vLyGC1yjJt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "7OvGefqm0d5c",
        "outputId": "af705e13-da18-436e-d649-9dad7eff9428"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/reddit.csv\")\n",
        "\n",
        "print('Number of sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "\n",
        "df.sample(5)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 1,000,000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab752138-f058-46a2-88e7-0f0fa2ca8188\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>987231</th>\n",
              "      <td>apexlegends</td>\n",
              "      <td>How ironic that you're being indignant on the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79954</th>\n",
              "      <td>ChapoTrapHouse</td>\n",
              "      <td>I started work in 99 when the boomers we're st...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567130</th>\n",
              "      <td>Market76</td>\n",
              "      <td>Any combination of the following:\\n\\nAAE Pump ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500891</th>\n",
              "      <td>worldnews</td>\n",
              "      <td>Compare pharma's marketing budget to it's R&amp;am...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55399</th>\n",
              "      <td>worldnews</td>\n",
              "      <td>Wasn't it an illegitimate election?</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab752138-f058-46a2-88e7-0f0fa2ca8188')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab752138-f058-46a2-88e7-0f0fa2ca8188 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab752138-f058-46a2-88e7-0f0fa2ca8188');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             subreddit  ... score\n",
              "987231     apexlegends  ...     0\n",
              "79954   ChapoTrapHouse  ...     2\n",
              "567130        Market76  ...     1\n",
              "500891       worldnews  ...     1\n",
              "55399        worldnews  ...     2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "redditデータセットの個々のカテゴリー(subreddit)に何個文章データが格納されているのかを知る。\n",
        "\n",
        "csvファイルの形式に応じて'subreddit' ,'body'を書き換える"
      ],
      "metadata": {
        "id": "z3hrn6egzOn7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvs-e334xQt",
        "outputId": "1e6d3ded-6bc9-4981-d5a8-8dbea9e4849f"
      },
      "source": [
        "print(\"subreddit多いもの順50\")\n",
        "count_df = df[['subreddit','body']].groupby('subreddit').aggregate({'body':'count'}).reset_index().sort_values('subreddit',ascending=True)\n",
        "print(count_df.head(50))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subreddit多いもの順50\n",
            "              subreddit   body\n",
            "0         AmItheAsshole  25000\n",
            "1              Animemes  25000\n",
            "2             AskReddit  25000\n",
            "3        ChapoTrapHouse  25000\n",
            "4            FortNiteBR  25000\n",
            "5              Market76  25000\n",
            "6          MortalKombat  25000\n",
            "7                Pikabu  25000\n",
            "8               RoastMe  25000\n",
            "9        Showerthoughts  25000\n",
            "10        SquaredCircle  25000\n",
            "11           The_Donald  25000\n",
            "12          apexlegends  25000\n",
            "13               asoiaf  25000\n",
            "14                  aww  25000\n",
            "15            dankmemes  25000\n",
            "16             freefolk  25000\n",
            "17                funny  25000\n",
            "18        gameofthrones  25000\n",
            "19               gaming  25000\n",
            "20             gonewild  25000\n",
            "21               hockey  25000\n",
            "22      leagueoflegends  25000\n",
            "23        marvelstudios  25000\n",
            "24                memes  25000\n",
            "25               movies  25000\n",
            "26                  nba  25000\n",
            "27                 news  25000\n",
            "28                  nfl  25000\n",
            "29                 pics  25000\n",
            "30             politics  25000\n",
            "31  relationship_advice  25000\n",
            "32               soccer  25000\n",
            "33            teenagers  25000\n",
            "34        todayilearned  25000\n",
            "35               trashy  25000\n",
            "36     unpopularopinion  25000\n",
            "37               videos  25000\n",
            "38       wallstreetbets  25000\n",
            "39            worldnews  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類に使う文章データのカテゴリーと量を決める。\n",
        "\n",
        "今回は2値分類なので2種類(df_0. df_1)用意した。"
      ],
      "metadata": {
        "id": "eaxl7WwmL2wt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4B_Ttt6VDaO",
        "outputId": "7133faa9-f0dc-45ff-80a7-fb0806c6d6f5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "\n",
        "# データの抽出\n",
        "df_0 = df.loc[df['subreddit'].isin(['news']), ['subreddit', 'body']]\n",
        "#どのカテゴリーを使うかを決めて、抽出したい情報(今回はカテゴリーを表すsubredditと文章を表すbody)を選ぶ\n",
        "df_0=df_0.replace('news',0)\n",
        "#以降の学習、検証ではint型のラベル名しかつけられないため、カテゴリーはint型の数値に置き換える\n",
        "split_dataset_0,discard_0=train_test_split(df_0, train_size=(5000/25000)) \n",
        "#必要な数だけ選択するために、train_test_splitを使ってsplit_dataset_0に分類に使う数のみ格納した\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_0)\n",
        "#分類に必要な数だけデータが揃っているか、カテゴリーを示すものがint型の数値になっているのかの2点を確認するためにsplit_dataset_0の中身の一部を出力する\n",
        "\n",
        "#もう1種類も同じように選択と抽出を行う\n",
        "df_1 = df.loc[df['subreddit'].isin(['worldnews']), ['subreddit', 'body']]\n",
        "df_1=df_1.replace('worldnews',1)\n",
        "split_dataset_1 ,discard_1= train_test_split(df_1, train_size=(5000/25000))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_1)\n",
        "\n",
        "#以降分類数を増やす際には上記の内容をコピー＆ペーストし、必要な箇所のみを書き換える\n",
        "\n",
        "list=[]\n",
        "#分類に使う全てのデータはリストで管理する\n",
        "list.append(split_dataset_0)\n",
        "#リストに分類で使うデータを追加する\n",
        "list.append(split_dataset_1)\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "#listの中にデータが格納されているかの確認を行う\n",
        "#出力結果から、カテゴリーを表す箇所がint型のデータになっているか、分類に必要な数が格納されているかを確認する\n",
        "print(df)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "697849          0                             They hate the economy?\n",
            "349138          0  It's not that common, it's pretty rare, and th...\n",
            "453339          0  &gt; Where did I say that only one people can ...\n",
            "27502           0  Both are obviously also much less effective th...\n",
            "517024          0  It's kind of surprising to read people (Semeny...\n",
            "...           ...                                                ...\n",
            "9046            0  I wondered this, too. It’s creating scarcity, ...\n",
            "749450          0  Well he's a cunt and everyone except his follo...\n",
            "376650          0  Kind of an odd juxtaposition though.  He dismi...\n",
            "119268          0  Why wouldn’t a criminal use their gun to defen...\n",
            "754965          0  But very easy to do with the computer generate...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "563659          1  We should also sanction them. But it's complic...\n",
            "337267          1                    Ya flooding sucks to be honest.\n",
            "422778          1             No it was a very poor attempt a humor.\n",
            "375867          1  No, per the DoJ per the article. Not Mueller. ...\n",
            "661054          1  I guess you took my safe bet comment literally...\n",
            "...           ...                                                ...\n",
            "375540          1  You don't know wtf you are talking about. It's...\n",
            "144623          1  I wouldn't know how their oil is, but I know t...\n",
            "362663          1  If you think apple would make more money tryin...\n",
            "223771          1  Not in this testimony. Here, Mueller is repeat...\n",
            "210109          1  I don't care about the title of this post or t...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "697849          0                             They hate the economy?\n",
            "349138          0  It's not that common, it's pretty rare, and th...\n",
            "453339          0  &gt; Where did I say that only one people can ...\n",
            "27502           0  Both are obviously also much less effective th...\n",
            "517024          0  It's kind of surprising to read people (Semeny...\n",
            "...           ...                                                ...\n",
            "375540          1  You don't know wtf you are talking about. It's...\n",
            "144623          1  I wouldn't know how their oil is, but I know t...\n",
            "362663          1  If you think apple would make more money tryin...\n",
            "223771          1  Not in this testimony. Here, Mueller is repeat...\n",
            "210109          1  I don't care about the title of this post or t...\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et6IqXeskSkn",
        "outputId": "2d12ca7f-34f3-4f6f-911a-36a2df05cae3"
      },
      "source": [
        "print(df.sample(5))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "664365          0  This is horseshit, just more fuel to add to th...\n",
            "726003          0  There was a professor back in the late 60's, e...\n",
            "151285          1  They must be mercenaries hired and equipped by...\n",
            "737447          0            You're so lost it's actually hilarious.\n",
            "670255          1  The issue is that the MCAS systems control ove...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hqjLnuCQnbfL",
        "outputId": "0e65d4c8-b33b-4f86-f7bb-ace3fef84d84"
      },
      "source": [
        "df.loc[df.subreddit == 0].sample(5)[['subreddit','body']]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9eabdf5f-a8b8-41a8-b263-cc0540c96e38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>584014</th>\n",
              "      <td>0</td>\n",
              "      <td>No, they should just go to jail and pay some f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212637</th>\n",
              "      <td>0</td>\n",
              "      <td>You only conceded a \"microscopic\" impact on an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207692</th>\n",
              "      <td>0</td>\n",
              "      <td>The vast majority, even in the United States (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610993</th>\n",
              "      <td>0</td>\n",
              "      <td>For southern states yes, and half the states d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160751</th>\n",
              "      <td>0</td>\n",
              "      <td>I feel like he’s not saying that’s good, he’s ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eabdf5f-a8b8-41a8-b263-cc0540c96e38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9eabdf5f-a8b8-41a8-b263-cc0540c96e38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9eabdf5f-a8b8-41a8-b263-cc0540c96e38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        subreddit                                               body\n",
              "584014          0  No, they should just go to jail and pay some f...\n",
              "212637          0  You only conceded a \"microscopic\" impact on an...\n",
              "207692          0  The vast majority, even in the United States (...\n",
              "610993          0  For southern states yes, and half the states d...\n",
              "160751          0  I feel like he’s not saying that’s good, he’s ..."
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.BERTでの分類に向けた準備"
      ],
      "metadata": {
        "id": "vWCsX31EXzR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークン化に向けて、カテゴリー(subreddit)と文章(body)を一旦別々のリストに格納する"
      ],
      "metadata": {
        "id": "OxQeo1a4OM0u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PBek_tnvi8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "文章(body)がbodysに格納され、カテゴリーとは別になっているかを確認する"
      ],
      "metadata": {
        "id": "82x6_lhpOV5I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM-JgfvrcU6",
        "outputId": "37a32f88-7502-46b4-d1fa-38930da38afe"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"It's not that common, it's pretty rare, and the only reason it seems common is because of 24/7 news. They play this shit non stop for days.\"\n",
            " \"&gt; Where did I say that only one people can be bigoted against a group? Where did I say it was “Nazis or nobody”?\\n\\nWhen you said:\\n\\n&gt;&gt;Yeah, cause we know that **the people** riling up anti-Semitic sentiment in the US are the freaking Palestinians.\\n\\n&gt;Where did I even claim that there weren’t Palestinians who didn’t like Jews?\\n\\nWhere you alluded it's the white nationalists in America that are *the* anti-semitic problem.  Period.  \\n\\n&gt;What I said was, in response to someone talking about the hypothetical problem of Palestinians whipping up anti-Semitic in the US, that if someone were worried about anti-semitism in the US, there are definitely other actors who should have their attention.\\n\\nWhere did they say they are solely focused on pro palestinian groups?  That's beyond an absurd assumption to make about Jews, that they're ignoring white nationalist neo-nazis.  Absolutely ridiculous.\"\n",
            " 'Both are obviously also much less effective than guns or they’d see more use today. Bombs are less accessible and more difficult to effectively use. Cars as well, not to mention we have a registry of pretty much every serviceable vehicle and who they belong to. Can’t say the same about guns. Classic whataboutism that has no footholds in reality. Better gun control would create a country with less gun crime. Full stop.'\n",
            " \"It's kind of surprising to read people (Semenya) claiming that elevated testosterone doesn't provide an advantage.\"\n",
            " 'Agreed that shortened casual speech assumes everyone listening is already familiar with the subject.   \"An attitude\" really refers to a hostile, aggressive, or otherwise bad attitude.  \\n\\nNow, \"reaching\" refers to reaching for something that might possibly, hypothetically, imaginably, arguably, inventively, or amazingly be used as weapon.'\n",
            " \"HI-Virus virus; PI-Number number; AT-Machine machine.\\n\\nOP was pointing out that the word 'virus', in the ~~headline~~ title, was redundant.\\n\\nEdit: Poster's title; the article headline has it right.\"\n",
            " \"He's in the mcu. He's ghost rider\"\n",
            " 'So good in jasmine tea though. Do you happen to know what other teas milk pairs with? Calling r/teaniggas'\n",
            " \"don't catch you slippin up\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTを使ってトークン化するので、BertTokenizerをロードする\n",
        "\n",
        "※最初にtransformersをインポートしていないとエラーが起こるので、必ずtransformersをインポートしてから行う\n",
        "\n",
        "トークン化に使う事前訓練モデルの選択もここで行う(bert-base-uncasedのこと)\n",
        "\n",
        "事前訓練モデルは他にも種類があるので、必要に応じて適切なものを選択する"
      ],
      "metadata": {
        "id": "yo9AhnTXOeTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GGzex042agA",
        "outputId": "a40dbdaa-02dd-437e-bf64-0d9eb27dd963"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT tokenizerの中身を確認する"
      ],
      "metadata": {
        "id": "kKCq2JkwPExK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWEoGPfoPpF",
        "outputId": "56bde903-f701-4bc2-f846-9e669eb09d7e"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークン化された内容の一例を出力する\n",
        "\n",
        "まず元の文章、2番目にはトークン化のために区切られrた文章、3番目には学習と検証のためにIDが割り振られたものが出力される。"
      ],
      "metadata": {
        "id": "ljgjD1bSPIkJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKYmw-zoUK6",
        "outputId": "1036872f-8f2c-46f3-fe8a-f70a497102d7"
      },
      "source": [
        "#元の文章\n",
        "print(' Original: ', bodys[1])\n",
        "#トークン化された文章\n",
        "print('Tokenized: ', tokenizer.tokenize(bodys[1]))\n",
        "#BERTが理解できるIDが割り振られた文章\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(bodys[1])))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  It's not that common, it's pretty rare, and the only reason it seems common is because of 24/7 news. They play this shit non stop for days.\n",
            "Tokenized:  ['it', \"'\", 's', 'not', 'that', 'common', ',', 'it', \"'\", 's', 'pretty', 'rare', ',', 'and', 'the', 'only', 'reason', 'it', 'seems', 'common', 'is', 'because', 'of', '24', '/', '7', 'news', '.', 'they', 'play', 'this', 'shit', 'non', 'stop', 'for', 'days', '.']\n",
            "Token IDs:  [2009, 1005, 1055, 2025, 2008, 2691, 1010, 2009, 1005, 1055, 3492, 4678, 1010, 1998, 1996, 2069, 3114, 2009, 3849, 2691, 2003, 2138, 1997, 2484, 1013, 1021, 2739, 1012, 2027, 2377, 2023, 4485, 2512, 2644, 2005, 2420, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "前のコードでは一つしかトークン化を行わなかったので、ここでは分類に使う全ての文章をトークン化する\n",
        "\n",
        "スペシャルトークン[SEP]と[MASK]はここで挿入を行う"
      ],
      "metadata": {
        "id": "kA8ZRK4kPn2y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUsAcl1EHw3F",
        "outputId": "71ff80b1-4af2-43d0-c9f1-174f4101a84f"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "#bodysに格納されている全ての文章に対して行う\n",
        "for sent in bodys:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                     \n",
        "                        add_special_tokens = True, \n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 64\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで学習用データと検証用データに分ける作業を行う\n",
        "\n",
        "train_test_splitを行うことで学習用データと検証用データに分割することができる\n",
        "\n",
        "test_sizeの値を調整すればどのくらいの割合で学習用データと検証用データを分けるかを変えられる"
      ],
      "metadata": {
        "id": "pd5HZJtxXOhf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38A6GW3kv5cf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_subreddits, validation_subreddits = train_test_split(input_ids, subreddits, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, subreddits,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分けた学習用データと検証用データをそれぞれのデータローダに格納する\n",
        "\n",
        "学習と検証はBERT modelを動かす時に全く別の段階で行うので、事前に分けておく必要がある"
      ],
      "metadata": {
        "id": "-yC9yb2gXTY7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdBvHg8wJQn"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_subreddits = torch.tensor(train_subreddits)\n",
        "validation_subreddits = torch.tensor(validation_subreddits)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "バッチサイズの定義を行い、その上で学習用、検証用それぞれのデータローダに格納を行う\n",
        "\n",
        "今回は推奨されている値で行なった"
      ],
      "metadata": {
        "id": "7R6-iV3YdmfY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIQ1JyFr80-Y"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size =32\n",
        "\n",
        "#学習用データをBERT modelが読み込めるデータローダーに格納する\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_subreddits)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "#評価用データをBERT modelが読み込めるデータローダーに格納する\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_subreddits)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルの構築の前に学習用、検証用のデータが必要数格納されているかを確認する"
      ],
      "metadata": {
        "id": "-tyxG-ulSkkp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGPGeiJUVujP",
        "outputId": "6d5c63c6-d5be-45c9-d1a5-26b68273c609"
      },
      "source": [
        "print(\"length of train data:\",len(train_data))\n",
        "print(\"length of validation data:\",len(validation_data))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of train data: 9000\n",
            "length of validation data: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.BERT modelの構築"
      ],
      "metadata": {
        "id": "0D0L1SGOX7Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "入力に使うデータが出揃ってから、BERT modelの構築を行う。\n",
        "\n",
        "モデルは必要に応じて適したものを選択する。\n",
        "\n",
        "pretrained modelはトークン化の前に定義したものと同じものを使う。\n",
        "\n",
        "num_labels は今回は2値分類なので2と示す。\n",
        "\n",
        "分類数に応じてnum_labelsの値を変える。"
      ],
      "metadata": {
        "id": "o7hSEeORXaNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XqEpQy7Gxb78"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GVNU1HErqst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c307d0fb-b3c0-43bb-eb49-6c288f16b475"
      },
      "source": [
        "#BERT modelを定義する\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, )\n",
        "#pytorchにこのモデルをGPU上で動かすために以下のコードで指示を出す\n",
        "model.cuda()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）\n",
        "学習と検証を行う前に一旦各変数の内容の確認を行う"
      ],
      "metadata": {
        "id": "YElRfc-STAKK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGbGAoaKsF3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f0144e-baa4-44d3-8281-111667f777f1"
      },
      "source": [
        "whos"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                          Type                             Data/Info\n",
            "----------------------------------------------------------------------------\n",
            "AdamW                             type                             <class 'transformers.optimization.AdamW'>\n",
            "BertConfig                        type                             <class 'transformers.mode<...>uration_bert.BertConfig'>\n",
            "BertForSequenceClassification     type                             <class 'transformers.mode<...>rSequenceClassification'>\n",
            "BertTokenizer                     type                             <class 'transformers.mode<...>tion_bert.BertTokenizer'>\n",
            "DataLoader                        type                             <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "MAX_LEN                           int                              64\n",
            "RandomSampler                     type                             <class 'torch.utils.data.sampler.RandomSampler'>\n",
            "SequentialSampler                 type                             <class 'torch.utils.data.<...>mpler.SequentialSampler'>\n",
            "TensorDataset                     type                             <class 'torch.utils.data.dataset.TensorDataset'>\n",
            "att_mask                          list                             n=64\n",
            "attention_masks                   list                             n=10000\n",
            "avg_train_loss                    float                            0.23530565076738807\n",
            "b_input_ids                       Tensor                           tensor([[  101,  2062, 14<...>    0]], device='cuda:0')\n",
            "b_input_mask                      Tensor                           tensor([[1, 1, 1, 1, 1, 1<...> 0, 0]], device='cuda:0')\n",
            "b_labels                          Tensor                           tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
            "batch                             tuple                            n=3\n",
            "batch_size                        int                              32\n",
            "bodys                             ndarray                          10000: 10000 elems, type `object`, 80000 bytes\n",
            "count_df                          DataFrame                                      subreddit  <...>         worldnews  25000\n",
            "datetime                          module                           <module 'datetime' from '<...>b/python3.7/datetime.py'>\n",
            "device                            device                           cuda\n",
            "df                                DataFrame                                subreddit        <...>n[10000 rows x 2 columns]\n",
            "df_0                              DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "df_1                              DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "discard_0                         DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "discard_1                         DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "elapsed                           str                              0:00:41\n",
            "encoded_sent                      list                             n=118\n",
            "epoch_i                           int                              3\n",
            "epochs                            int                              4\n",
            "eval_accuracy                     float64                          23.65625\n",
            "eval_loss                         int                              0\n",
            "flat_accuracy                     function                         <function flat_accuracy at 0x7f3c5312fb90>\n",
            "format_time                       function                         <function format_time at 0x7f3c5312f710>\n",
            "get_linear_schedule_with_warmup   function                         <function get_linear_sche<...>warmup at 0x7f3c529c25f0>\n",
            "input_ids                         ndarray                          10000x64: 640000 elems, type `int64`, 5120000 bytes (4.8828125 Mb)\n",
            "label_ids                         ndarray                          8: 8 elems, type `int64`, 64 bytes\n",
            "list                              list                             n=2\n",
            "logits                            ndarray                          8x2: 16 elems, type `float32`, 64 bytes\n",
            "loss                              Tensor                           tensor(0.4033, device='cu<...>ad_fn=<NllLossBackward0>)\n",
            "loss_values                       list                             n=4\n",
            "model                             BertForSequenceClassification    BertForSequenceClassifica<...>features=2, bias=True)\\n)\n",
            "nb_eval_examples                  int                              0\n",
            "nb_eval_steps                     int                              32\n",
            "np                                module                           <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "optimizer                         AdamW                            AdamW (\\nParameter Group <...>n    weight_decay: 0.0\\n)\n",
            "outputs                           SequenceClassifierOutput         SequenceClassifierOutput(<...>es=None, attentions=None)\n",
            "p                                 tuple                            n=2\n",
            "pad_sequences                     function                         <function pad_sequences at 0x7f3d605c05f0>\n",
            "params                            list                             n=201\n",
            "pd                                module                           <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "random                            module                           <module 'random' from '/u<...>lib/python3.7/random.py'>\n",
            "scheduler                         LambdaLR                         <torch.optim.lr_scheduler<...>object at 0x7f3c54426410>\n",
            "seed_val                          int                              42\n",
            "sent                              ndarray                          64: 64 elems, type `int64`, 512 bytes\n",
            "split_dataset_0                   DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "split_dataset_1                   DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "step                              int                              281\n",
            "subreddits                        ndarray                          10000: 10000 elems, type `int64`, 80000 bytes\n",
            "t0                                float                            1642579216.6404803\n",
            "tf                                module                           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
            "time                              module                           <module 'time' (built-in)>\n",
            "tmp_eval_accuracy                 float64                          0.875\n",
            "tokenizer                         BertTokenizer                    PreTrainedTokenizer(name_<...> 'mask_token': '[MASK]'})\n",
            "torch                             module                           <module 'torch' from '/us<...>kages/torch/__init__.py'>\n",
            "total_loss                        float                            66.35619351640344\n",
            "total_steps                       int                              1128\n",
            "train_data                        TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f3c5441d810>\n",
            "train_dataloader                  DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f3c5441ddd0>\n",
            "train_inputs                      Tensor                           tensor([[  101,  2043,  2<...>.,     0,     0,     0]])\n",
            "train_masks                       Tensor                           tensor([[1, 1, 1,  ..., 0<...>1, 1, 1,  ..., 0, 0, 0]])\n",
            "train_sampler                     RandomSampler                    <torch.utils.data.sampler<...>object at 0x7f3c5441de90>\n",
            "train_subreddits                  Tensor                           tensor([1, 0, 0,  ..., 0, 0, 1])\n",
            "train_test_split                  function                         <function train_test_split at 0x7f3c3fdc9d40>\n",
            "validation_data                   TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f3c5441dcd0>\n",
            "validation_dataloader             DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f3c5441db90>\n",
            "validation_inputs                 Tensor                           tensor([[  101,  2149,  1<...>.,  2763,  3308,  1010]])\n",
            "validation_masks                  Tensor                           tensor([[1, 1, 1,  ..., 0<...>1, 1, 1,  ..., 1, 1, 1]])\n",
            "validation_sampler                SequentialSampler                <torch.utils.data.sampler<...>object at 0x7f3c5441dd90>\n",
            "validation_subreddits             Tensor                           tensor([1, 0, 0, 0, 1, 1,<...> 1, 1, 1, 1, 1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）もし学習と検証の段階でcuda errorが起こった場合、その原因がおそらくlistと考えられる\n",
        "\n",
        "以降ではlistの中身を使うことがないので削除して問題ない"
      ],
      "metadata": {
        "id": "ds-YJcCSTKve"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vnKQq1sHuc"
      },
      "source": [
        "del list"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTモデルの中身及びパラメータを確認する時には以下のセルを実行する"
      ],
      "metadata": {
        "id": "jw3ss3B-QOSt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXobR03zsHyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee10ffa-7629-4804-f94e-a44ca69b5162"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizerの値を決定する(今回はHugging Faceが推奨する値で行なったが、変更も可能)"
      ],
      "metadata": {
        "id": "hnDPEBZXQU3h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmmZgnesJb0"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "エポック数を決める(今回はHugging Faceが推奨する値で行なったが、変更も可能)"
      ],
      "metadata": {
        "id": "RDdt6sCMQZrh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJLAsdgZsL_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6a6b8e-e812-47bd-b9d9-896e77cbac0b"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f3c566561d0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解率の計算式を定義する(今回はHugging Faceが推奨する式で行なったが、場合に応じては変更も可能)\n"
      ],
      "metadata": {
        "id": "oAtYrNAjQbE8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMgLdT0LsO8t"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）学習と検証にかかった時間を知るために、時間の計算の値を返すように設定する"
      ],
      "metadata": {
        "id": "vGhs-cXrQfY-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FJbbti9sSNW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    #フォーマットは hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.学習と検証を行う\n"
      ],
      "metadata": {
        "id": "8qSUEuC4Qsp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#(推奨事項)損失関数を格納するためのリストを作る\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "  \n",
        "    #=======================#\n",
        "\n",
        "                #学習\n",
        "\n",
        "    #=======================#\n",
        " \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    #(推奨事項)学習時間の計測を行う\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    #学習のためのモデルを動かす\n",
        "    model.train()\n",
        "\n",
        "    #(推奨事項)学習の進捗状況を出力する\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    #(推奨事項)損失関数の計算を行う\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    #(推奨事項)各epochで得られた損失関数をlistに格納する\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "\n",
        "    #=======================#\n",
        "\n",
        "                #検証\n",
        "                \n",
        "    #=======================#\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #(推奨事項)検証にかかった時間を計算する\n",
        "    #学習にかかった時間が入っているので一度リセットする\n",
        "    t0 = time.time()\n",
        "\n",
        "    #検証のためのモデルを動かす\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          \n",
        "          with torch.no_grad():\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "          \n",
        "          logits = outputs[0]\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "\n",
        "        \n",
        "          #正解率の計算を行う\n",
        "          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "          eval_accuracy += tmp_eval_accuracy\n",
        "          nb_eval_steps += 1\n",
        "\n",
        "    #検証結果の出力を行う\n",
        "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2YU-N8mAFZY",
        "outputId": "3b7fdaf1-1640-4075-a481-7052943ceba6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.5718\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7275\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.4520\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7441\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.3229\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7402\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.2353\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7393\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）損失関数を求める"
      ],
      "metadata": {
        "id": "-coS3-huTsR7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDepN0AbHIef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590897a7-a823-472a-a50c-2ca28c4b5c1f"
      },
      "source": [
        "loss_values"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5718240374368979,\n",
              " 0.45201769872760095,\n",
              " 0.32286586633599396,\n",
              " 0.23530565076738807]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "（推奨事項）損失関数によるグラフの作成"
      ],
      "metadata": {
        "id": "b8xoHSxrTvA0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1alxJ4duxCA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "493740c7-4709-4fce-af11-8ba84e9fdccc"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"298a1340-df37-44c7-b557-637730f0b828\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"298a1340-df37-44c7-b557-637730f0b828\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '298a1340-df37-44c7-b557-637730f0b828',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"xaxis\": \"x\", \"y\": [0.5718240374368979, 0.45201769872760095, 0.32286586633599396, 0.23530565076738807], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('298a1340-df37-44c7-b557-637730f0b828');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類器を構築し、性能評価を行う段階は以上。\n",
        "\n",
        "以降は分類器をテストする際に実行をしたプログラムである。\n",
        "\n",
        "テスト用のipynbファイルを作り直すと、学習と検証のために使った分類器の内容が消されてしまうので、テストを行うのであれば、同一のipynbファイル内で実行する必要がある。"
      ],
      "metadata": {
        "id": "VMfMBMpxTyK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.テスト"
      ],
      "metadata": {
        "id": "T6_wteB3YZ5I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELlVP2ZmbEs"
      },
      "source": [
        "テストを行う際には以下のセルを実行する\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "学習と検証用に選択したカテゴリー名と同一のものをテストでも使う必要がある。\n",
        "\n",
        "先程1カテゴリー25000から使用しなかった20000個から抽出をした。\n",
        "\n",
        "これによって学習と検証で使ったデータをテストでも重複して使うということをなくした。\n",
        "\n",
        "テストの前段階では学習と検証に用いた文章データと同様にBERTに入力できるように設定をした。\n",
        "\n",
        "テストを終えた後では、テスト結果から得られた数値を求め、可視化を行なった。"
      ],
      "metadata": {
        "id": "SXfNp3eMYcuk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTBmN-I0dZbT",
        "outputId": "08b03fb5-0f36-46c0-d850-b9f4d38fac2a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_dataset_test_0,discard_test_0=train_test_split(discard_0, train_size=(1000/(25000-5000))) \n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_0)\n",
        "\n",
        "split_dataset_test_1 ,discard_test_1= train_test_split(discard_1, train_size=(1000/(25000-5000)))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_1)\n",
        "\n",
        "\n",
        "list=[]\n",
        "list.append(split_dataset_test_0)\n",
        "list.append(split_dataset_test_1)\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "print(df)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "565955          0  Most of the time these things aren't blackface...\n",
            "87685           0  Just that we have phones now news can be wides...\n",
            "28561           0  All of that is covered by the phrase \"backgrou...\n",
            "209735          0  Yeah the 1994 Assault Weapons Ban was in effec...\n",
            "436782          0  I didn't read the article so saying that. Who ...\n",
            "...           ...                                                ...\n",
            "354427          0  &gt;Going to school one day and getting gunned...\n",
            "313386          0  Yall should be allowed to sit back and crack a...\n",
            "502113          0  Paid 46 million? I don't think so.\\n\\nSome peo...\n",
            "377405          0                     Bahhahhaha I spit my water out\n",
            "767369          0  I don't know if you know this but apple has so...\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "209448          1                         You seem a little nervous.\n",
            "349372          1  Did I say white cops never shot anyone? No. I ...\n",
            "625072          1  No, its a term used to describe an inconvenien...\n",
            "169576          1                   Mueller's full of shit isn't he?\n",
            "397986          1  And capitalist countries aren’t? Maybe you sho...\n",
            "...           ...                                                ...\n",
            "641332          1  Senator Ben Sasse (R) at least seemed genuinel...\n",
            "465967          1  This just encourages US imperialism further wh...\n",
            "313350          1  He is still right technically. They have this ...\n",
            "586531          1  Impeachment is in the House. Are all the comme...\n",
            "248241          1  Would be excited to see a change-up in this ma...\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "565955          0  Most of the time these things aren't blackface...\n",
            "87685           0  Just that we have phones now news can be wides...\n",
            "28561           0  All of that is covered by the phrase \"backgrou...\n",
            "209735          0  Yeah the 1994 Assault Weapons Ban was in effec...\n",
            "436782          0  I didn't read the article so saying that. Who ...\n",
            "...           ...                                                ...\n",
            "641332          1  Senator Ben Sasse (R) at least seemed genuinel...\n",
            "465967          1  This just encourages US imperialism further wh...\n",
            "313350          1  He is still right technically. They have this ...\n",
            "586531          1  Impeachment is in the House. Are all the comme...\n",
            "248241          1  Would be excited to see a change-up in this ma...\n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7PuJIGM342n",
        "outputId": "1d3781b8-00f1-4c90-fdfa-554a5c564c3f"
      },
      "source": [
        "print(df.sample(5))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "73458           0  Yeah, I was looking at the 2016-17 dataset. In...\n",
            "398478          0  So your counter-argument to taking steps to cu...\n",
            "70633           0  I’m sure everyone retakes it. The prof was pro...\n",
            "176383          0  Not really, one guy got a notification on his ...\n",
            "741333          0  Mass media, over medication, hopeless future, ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfHQ3AmN342n"
      },
      "source": [
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5guwNZIF342n",
        "outputId": "4fd7db4e-538c-4bf5-dd78-1eb7d3284440"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Just that we have phones now news can be widespread quickly and news sites posting in big bold letters in the title with shooters name and kill count so it inspires new shooters to come in.'\n",
            " 'All of that is covered by the phrase \"background check\" my man. I haven\\'t dug deep enough to verify, but I saw something that said it takes up to 3 days to run the background check when buying a gun at Walmart (which we are talking about Walmart here, and Walmart couldn\\'t give two shits about a gut feeling). Regardless, my point was that all you have to do differently to buy a gun than to buy milk is fill out a form or two. You do not have to jump through hoops like you\\'re making it sound. You fill out some forms and wait, that\\'s it. If you\\'ve got a clean record and are old enough you\\'ll get your gun, otherwise no gun for you. A lot of these mass shooters don\\'t have criminal history, especially these young kids that are shooting up schools. Even the older shooters sometimes have no criminal record - the Las Vegas shooter was 64 years old and nobody would have stopped him from buying a gun based on a background check.'\n",
            " 'Yeah the 1994 Assault Weapons Ban was in effect and they used banned weapons. Including but not limited to: sawed off shotguns and a Tec9.'\n",
            " \"I didn't read the article so saying that. Who the hell at NASA was doing quality control?? They should absolutely caught the aluminum was of bad quality, too thin,wrong chemical make up and so on that's what QC is responsible for. If they cant catch bad aluminum  then god help our astronauts. Oh wait ,how many were lost in the shuttle program??\"\n",
            " 'Or undercover GOV sabotage conspiracy.'\n",
            " \"she's all good. thank you for your support. she's a TA, grad student there was teaching at the time. My aunt said she hid all of the kids and was brave.\"\n",
            " 'Vaccination article on my front page even though it was just submitted?  First time for everything!'\n",
            " 'Well apparently 316 people have been shot and killed by police alone in US this year so far. This is around a decade worth of police shootings in whole of the EU. So yeah tell me more how your \"government\" is not killing people and owning small arms helps.\\n\\nAlso nice going bringing NK to the discussion, like there is no other country in the world that has strict gun laws and still enjoys better democracy than what you have in US (yes your \"democracy\" is not very democratic)'\n",
            " \"Seems likely to me that a 'rape attic' is just a dingy dimly lit attic, that was jokingly called the rape attic strictly due to appearance.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTでの分類に向けた準備\n",
        "\n",
        "テスト用データでもBERTでの分類に適した形にデータのトークン化を行なった"
      ],
      "metadata": {
        "id": "1agWTQXoqB2Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFwF6uHz342n"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in bodys:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                    \n",
        "                        add_special_tokens = True,\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用のデータを分類器に入力をするための準備を行う。"
      ],
      "metadata": {
        "id": "WtMO0k9OoeaL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkHGueVUWa-"
      },
      "source": [
        "test_inputs=input_ids\n",
        "test_subreddits=subreddits\n",
        "test_masks=attention_masks"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcBvuNdyUWa_"
      },
      "source": [
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "test_subreddits = torch.tensor(test_subreddits)\n",
        "\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_HT2vZA9MiQ"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgUaHNRt3qa6"
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyKPEEo36tw0",
        "outputId": "27b81a7f-4492-4412-c963-436e4eae8e96"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cudaが使えるかどうかの確認を行う"
      ],
      "metadata": {
        "id": "x4AeiAdNhYnA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NV-eVNIql9C",
        "outputId": "b5a346b8-c149-41d1-a979-c1a3a3d495ba"
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G20kBKPKqyAj",
        "outputId": "52439c4b-4557-494c-e953-ad04e3194430"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用データを使って分類を行う\n",
        "\n",
        "分類器は先程学習と検証を行なったものを呼び出して行う"
      ],
      "metadata": {
        "id": "QLzMOCZUSo81"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIh7osycmZJr",
        "outputId": "3439c16a-5498-4349-91e4-9bbf0b4a1d1d"
      },
      "source": [
        "#=======================#\n",
        "\n",
        "             #テスト\n",
        "                \n",
        "#=======================#\n",
        "\n",
        "#(推奨事項)テストにかかった時間を計算する\n",
        "t0 = time.time()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "    b_input_ids =test_inputs\n",
        "    b_input_mask = test_masks\n",
        "    b_labels = test_subreddits\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_input_mask = b_input_mask.to(device)\n",
        "    b_labels = b_labels.to(device)\n",
        "    \n",
        "    with torch.no_grad():   \n",
        "        # 学習済みモデルによる予測結果をpredsで取得する     \n",
        "      preds = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask)\n",
        "\n",
        "print(\"time took : {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time took : 0:01:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*テスト結果の確認*"
      ],
      "metadata": {
        "id": "I4Cpand7NFtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト用データによる分類結果をlogits_dfに入れる\n",
        "\n",
        "予測ラベルと正解ラベルのデータも同様にpred_dfとlabel_dfに入れる\n",
        "\n",
        "３つのデータをaccuracy_dfに入れることでテスト結果の一部を見れるようにする\n",
        "\n",
        "今回テストに用いた2000個の文章データ1つ1つが、テストをした結果どこのカテゴリー名であると割り振られ、実際にはどこのカテゴリー名であったかをaccuracy_dfを得ることによって確認ができる"
      ],
      "metadata": {
        "id": "Vp-xlFibSxx0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wLTnxlUmsPbl",
        "outputId": "286cc67b-a83d-45c7-98f7-af07fd098b41"
      },
      "source": [
        "# 比較しやすい様にpd.dataframeへ整形\n",
        "import pandas as pd\n",
        "\n",
        "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "logits_df = pd.DataFrame(preds[0].cpu().numpy() )\n",
        "## np.argmaxで大き方の値を取得\n",
        "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "accuracy_df.head(10)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15052b32-64c4-488b-aec5-ffbe4f5bd1a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.569540</td>\n",
              "      <td>0.392543</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.618046</td>\n",
              "      <td>0.208999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.546226</td>\n",
              "      <td>0.270315</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.477165</td>\n",
              "      <td>0.352140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.619432</td>\n",
              "      <td>0.221963</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.492045</td>\n",
              "      <td>0.427344</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.557501</td>\n",
              "      <td>0.385695</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.442965</td>\n",
              "      <td>0.515909</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.659166</td>\n",
              "      <td>0.156303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.641499</td>\n",
              "      <td>0.276110</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15052b32-64c4-488b-aec5-ffbe4f5bd1a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15052b32-64c4-488b-aec5-ffbe4f5bd1a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15052b32-64c4-488b-aec5-ffbe4f5bd1a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          0         1  pred_label  true_label\n",
              "0  0.569540  0.392543           0           0\n",
              "1  0.618046  0.208999           0           0\n",
              "2  0.546226  0.270315           0           0\n",
              "3  0.477165  0.352140           0           0\n",
              "4  0.619432  0.221963           0           0\n",
              "5  0.492045  0.427344           0           0\n",
              "6  0.557501  0.385695           0           0\n",
              "7  0.442965  0.515909           1           0\n",
              "8  0.659166  0.156303           0           0\n",
              "9  0.641499  0.276110           0           0"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を元に混合行列を作る\n",
        "\n",
        "ここでは混合行列を数値データで出力する"
      ],
      "metadata": {
        "id": "HMNj5tVURW17"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67oSJwJzPJZo",
        "outputId": "234656f7-d2be-4333-c715-6650782d85bd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmatrix = confusion_matrix(label_df,pred_df)\n",
        "print(cmatrix)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[875 125]\n",
            " [863 137]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要に応じて混合行列を図として出力する"
      ],
      "metadata": {
        "id": "_C6svBwbRDSw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "kU4_9ymEwccX",
        "outputId": "9f5c27d0-8330-4ffb-e60f-af5f31c1ce97"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"low cos similality 2 classes\")\n",
        "plt.rcParams[\"font.size\"] = 16\n",
        "sns.heatmap(cmatrix, cmap= sns.color_palette('rainbow', 50), annot=True,fmt='.0f',vmin=0,vmax=1000)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b725c6790>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUjbDLdApmn"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を数値で出力する"
      ],
      "metadata": {
        "id": "Ka8LXEHVRiiP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3JdR0Mw_EvD",
        "outputId": "b40e08b2-302c-4b43-9730-78cab1a41c87"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification report\")\n",
        "print(classification_report(label_df,pred_df))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.88      0.64      1000\n",
            "           1       0.52      0.14      0.22      1000\n",
            "\n",
            "    accuracy                           0.51      2000\n",
            "   macro avg       0.51      0.51      0.43      2000\n",
            "weighted avg       0.51      0.51      0.43      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8e7qeW9jYP",
        "outputId": "9fe6d0a7-9a98-4d9e-a15a-c5fa527e6a27"
      },
      "source": [
        "import pprint\n",
        "d = metrics.classification_report(label_df,pred_df, output_dict=True)\n",
        "pprint.pprint(d)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'f1-score': 0.6391526661796931,\n",
            "       'precision': 0.503452243958573,\n",
            "       'recall': 0.875,\n",
            "       'support': 1000},\n",
            " '1': {'f1-score': 0.21711568938193343,\n",
            "       'precision': 0.5229007633587787,\n",
            "       'recall': 0.137,\n",
            "       'support': 1000},\n",
            " 'accuracy': 0.506,\n",
            " 'macro avg': {'f1-score': 0.4281341777808133,\n",
            "               'precision': 0.5131765036586758,\n",
            "               'recall': 0.506,\n",
            "               'support': 2000},\n",
            " 'weighted avg': {'f1-score': 0.42813417778081325,\n",
            "                  'precision': 0.5131765036586758,\n",
            "                  'recall': 0.506,\n",
            "                  'support': 2000}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "テスト結果を表で出力する"
      ],
      "metadata": {
        "id": "u0n0DwIXSftu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "VuCTI965HfkZ",
        "outputId": "a1b4feef-b468-4e00-cf2d-0d4cf7a39704"
      },
      "source": [
        "df = pd.DataFrame(d)\n",
        "df"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-149d8e4c-1201-4369-883d-19971fb9529a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.503452</td>\n",
              "      <td>0.522901</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.513177</td>\n",
              "      <td>0.513177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.137000</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.506000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.639153</td>\n",
              "      <td>0.217116</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.428134</td>\n",
              "      <td>0.428134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.506</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-149d8e4c-1201-4369-883d-19971fb9529a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-149d8e4c-1201-4369-883d-19971fb9529a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-149d8e4c-1201-4369-883d-19971fb9529a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     0            1  accuracy    macro avg  weighted avg\n",
              "precision     0.503452     0.522901     0.506     0.513177      0.513177\n",
              "recall        0.875000     0.137000     0.506     0.506000      0.506000\n",
              "f1-score      0.639153     0.217116     0.506     0.428134      0.428134\n",
              "support    1000.000000  1000.000000     0.506  2000.000000   2000.000000"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要に応じてテスト結果を図で出力する"
      ],
      "metadata": {
        "id": "6qYpyTnqSiiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 12\n",
        "plt.title(\"low cos similality 2 classes\")\n",
        "sns.heatmap(df, cmap= sns.color_palette('rainbow', 40), annot=True,fmt='.4f',vmin=0,vmax=1,linewidths=1,linecolor='white')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "Z0wKPhhxSas2",
        "outputId": "6fc1d788-a8e6-4d1b-feab-d26ad83cc0a0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b72dde0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}